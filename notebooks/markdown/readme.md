
### Text Preprocessing with Tokenization

There are 3 variants of tokenization.

<div align="center">
  <img src="https://user-images.githubusercontent.com/33477318/133191674-0fbc1cf0-7bf3-4744-bd00-2cfb738eafb0.png" alt="tokenization" width="500" >
</div> 


### Install tokenizer of the latest version
```
python -m pip install tokenizers 
```
<div align="center">
  <img alt="tokenizerlib" src="https://user-images.githubusercontent.com/33477318/133194286-0dbf86aa-8746-4a03-9dfb-8f86531babf4.png" width="600"><br>
</div> 




